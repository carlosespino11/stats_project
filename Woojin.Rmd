---
title: "Report"
author: "Carlos Espino, Xavier Gonzalez, Diego Llarrull, Woojin Kim"
date: "December 14, 2015"
graphics: yes
output:
  pdf_document:
    toc: true
---
```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.width=12, fig.height=8, fig.path='Figs/',
                      echo=FALSE, warning=FALSE, message=FALSE)
```
\clearpage

# Introduction
Understanding the factors behind criminal behaviour is one of the most crucial task for preventing and controlling future crime. In this report, we explore the potential factors affecting crime rates based on the demographics and econometrics data gathered from 197 counties in North Carolina from 1981 to 1987. Using various statistical methods and modeling techniques, we analyze and identify the most important factors and metrics tied to crime rates. We also present a predictive model capable of estimating the crime rate with under 25% error using the selected parameters.

# Dataset
| Predictor| Description                                                                    |   |
|----------|--------------------------------------------------------------------------------|---|
| county   | county identifier                                                              |   |
| year     | year from 1981 to 1987                                                         |   |
| crmrte   | crimes committed per person                                                    |   |
| prbarr   | 'probability' of arrest                                                        |   |
| prbconv  | 'probability' of conviction                                                    |   |
| prbpris  | 'probability' of prison sentence                                               |   |
| avgsen   | average sentence, days                                                         |   |
| polpc    | police per capita                                                              |   |
| density  | people per square mile                                                         |   |
| taxpc    | tax revenue per capita                                                         |   |
| region   | one of 'other', 'west' or 'central'                                            |   |
| smsa     | 'yes' or 'no' if in SMSA                                                       |   |
| pctmin   | percentage minority in 1980                                                    |   |
| wcon     | weekly wage in construction                                                    |   |
| wtuc     | weekly wage in trns, util, commun                                              |   |
| wtrd     | weekly wage in whole sales and retail trade                                    |   |
| wfir     | weekly wage in finance, insurance and real estate                              |   |
| wser     | weekly wage in service industry                                                |   |
| wmfg     | weekly wage in manufacturing                                                   |   |
| wfed     | weekly wage of federal emplyees                                                |   |
| wsta     | weekly wage of state employees                                                 |   |
| wloc     | weekly wage of local governments employees mix offence mix: face-to-face/other |   |
| pctymle  | percentage of young males                                                      |   |
\begin{center}Table 1: Description of the predictors in the dataset\end{center}

```{r, echo=FALSE}
library(ISLR)
library(leaps)
library(glmnet)
library(caret)
library(MASS)
library(grid)
library(ggplot2)
library(splines)
library(caret)
library(knitr)

load("ggthemes_data.rda")
source("theme_fivethirtyeight.R")
Crime <- read.csv("Crime.csv")
Crime = Crime[,-1] # Remove the index column

# Identify and remove the outliers found from later analyses
# fit.all <- lm(crmrte~bs(pctmin, knots=pctmin.knots) + log(prbconv) + log(polpc) + prbarr + density:county + prbarr:prbpris + pctmin:polpc + polpc:wfed + density:pctmin + density:pctymle + taxpc:wfed + region:wsta, data=Crime)
bad = c(440,353,437,439)
Crime = Crime[-bad,]
```

# Non-linear modeling
From the pairwise plot we generated shown in (), we identified a predictor `pctmin`, corresponding to the proportion of minorities in the region, showing a clear non-linear relationship with the crime rate that can benefit from higher order polynomial regression/splines and also help with predicting the overall crime rate.

## Linear model
First we evaluated the regression model generated using only using a linear model:

```{r, echo=FALSE}
##########
# Setup
##########
# Split into training/test sets
set.seed(1)
index.test = sample(nrow(Crime), nrow(Crime)*.20)
Crime.train = Crime[-index.test,]
Crime.test = Crime[index.test,]

# k-Folds (k=10)
folds = createFolds(Crime.train$pctmin, k=10, list=TRUE, returnTrain=FALSE)
```

```{r}
# Only linear $pctmin
# Only linear $pctmin
fit.lin = list()
pred.lin = list()
kf.error.lin = vector()
for (i in 1:length(folds)) {
  fit.lin[[i]] = lm(crmrte ~ pctmin, data=Crime.train[-folds[[i]],])
  pred.lin = predict(fit.lin[[i]], newdata=Crime.train[folds[[i]],])
  test.lin.k = Crime.train[folds[[i]],]$crmrte
  kf.error.lin[i] = mean(abs((pred.lin - test.lin.k)/test.lin.k))
}
best.index.lin = which.min(kf.error.lin)
pred.lin = predict(fit.lin[[best.index.lin]], newdata=Crime.test)
error.lin = mean(abs((pred.lin-Crime.test$crmrte)/Crime.test$crmrte))
```

```{r out.width='350px', fig.align='center'}
# Plot
base.plot = ggplot() + geom_point(aes(x = Crime$pctmin, y = Crime$crmrte), color="darkgrey") + 
  labs(x="Proportion of minority in 1980 (%)", y="Crimes committed per person") +
  theme_fivethirtyeight()
base.plot +
  geom_line(aes(x = Crime.test$pctmin, y = pred.lin), color="red") +
  ggtitle("Linear model for crime rate vs. proportion of minorities")
```
\begin{center} Figure 1: Linear model for crime rate vs. proportion of minorities \end{center}

This naÃ¯ve model results in an error rate of `r round(error.lin,4)` for the testing set. From the plot it is very clear that the relationship between the crime rate and the proportion of minorities in the area is not linear. 

## Polynomial model
Next we obtained a degree-4 polynomial fit for a smooth fit over the `pctmin` data:

```{r}
# Only polynomial $pctmin
fit.poly = list()
pred.poly = list()
kf.error.poly = vector()
for (i in 1:length(folds)) {
  fit.poly[[i]] = lm(crmrte ~ poly(pctmin,4), data=Crime.train[-folds[[i]],])
  pred.poly = predict(fit.poly[[i]], newdata=Crime.train[folds[[i]],])
  test.poly.k = Crime.train[folds[[i]],]$crmrte
  kf.error.poly[i] = mean(abs((pred.poly - test.poly.k)/test.poly.k))
}
best.index.poly = which.min(kf.error.poly)
pred.poly = predict(fit.poly[[best.index.poly]], newdata=Crime.test)
error.poly = mean(abs((pred.poly-Crime.test$crmrte)/Crime.test$crmrte))
```

```{r out.width='350px', fig.align='center'}
# Plot
base.plot +
  geom_line(aes(x = Crime.test$pctmin, y = pred.poly), color="red") +
  ggtitle("Degree-4 polynomial model for crime rate vs. proportion of minorities")
```
\begin{center} Figure 2: Degree-4 polynomial model for crime rate vs. proportion of minorities \end{center}

The error rate was improved by reducing the bias of the model. This fit resulted in an error rate of `r round(error.poly,4)`.

## Splines
```{r}
# Natural spline knots
pctmin.knots = attr(ns(Crime.train$pctmin, df=6), "knots")

# Only splines $pctmin
fit.spl = list()
pred.spl = list()
kf.error.spl = vector()
for (i in 1:length(folds)) {
  fit.spl[[i]] = lm(crmrte ~ ns(pctmin, knots=pctmin.knots), data=Crime.train[-folds[[i]],])
  pred.spl = predict(fit.spl[[i]], newdata=Crime.train[folds[[i]],])
  test.spl.k = Crime.train[folds[[i]],]$crmrte
  kf.error.spl[i] = mean(abs((pred.spl - test.spl.k)/test.spl.k))
}
best.index.spl = which.min(kf.error.spl)
pred.spl = predict(fit.spl[[best.index.spl]], newdata=Crime.test, se.fit=TRUE)
error.spl = mean(abs((pred.spl$fit-Crime.test$crmrte)/Crime.test$crmrte))
```
We further attempt to reduce the bias, introducing a more flexible piecewise polynomial by using knots. Using a cubic spline, the fitted curves are constrained to be continuous. As splines often leads to high variance at the outern ranges of the predictors, we fit natural cubic spline, which forces the function to be linear at the boundary. `ns()` function was used to generate natural cubic knots with 6 degrees of freedom, with matrix of basis functions for splines and knots at `r round(pctmin.knots[1],2)`%, `r round(pctmin.knots[2],2)`%, `r round(pctmin.knots[3],2)`%, `r round(pctmin.knots[4],2)`%, and `r round(pctmin.knots[5],2)`% of `pctmin`.

```{r out.width='350px', fig.align='center'}
# Plot
base.plot +
  geom_ribbon(aes(x = Crime.test$pctmin, y = pred.spl$fit, ymin=pred.spl$fit-2*pred.spl$se, ymax=pred.spl$fit+2*pred.spl$se), color="lightgrey", alpha=.15) +
  geom_line(aes(x = Crime.test$pctmin, y = pred.spl$fit), color="red") +
  geom_line(aes(x = Crime.test$pctmin, y = pred.spl$fit+2*pred.spl$se), linetype = "dashed") +
  geom_line(aes(x = Crime.test$pctmin, y = pred.spl$fit-2*pred.spl$se), linetype = "dashed") +
  ggtitle("Natural cubic splines model for crime rate vs. proportion of minorities")
```
\begin{center}
Figure 3: Natural cubic splines model for crime rate vs. proportion of minorities
\end{center}

Consequently, we see a modest improvement in the mean error: `r round(error.spl,4)`.

We also attempted to fit a smoothing spline with a value of $\lambda$ chosen cross-validation. This resulted in a model very similar to the polynomial fit and failed to improve the mean $k$-folds cross-validation error.

```{r}
# Linear $pctmin with selected predictors
fit.lin2 = list()
pred.lin2 = list()
kf.error.lin2 = vector()
for (i in 1:length(folds)) {
  fit.lin2[[i]] = lm(crmrte~pctmin + log(prbconv) + log(polpc) + prbarr + density:county + 
                       prbarr:prbpris + pctmin:polpc + polpc:wfed + density:pctmin +
                       density:pctymle + taxpc:wfed + region:wsta, data=Crime.train[-folds[[i]],])
  pred.lin2 = predict(fit.lin2[[i]], newdata=Crime.train[folds[[i]],])
  test.lin2.k = Crime.train[folds[[i]],]$crmrte
  kf.error.lin2[i] = mean(abs((pred.lin2 - test.lin2.k)/test.lin2.k))
}
best.index.lin2 = which.min(kf.error.lin2)
pred.lin2 = predict(fit.lin2[[best.index.lin2]], newdata=Crime.test)
error.lin2 = mean(abs((pred.lin2-Crime.test$crmrte)/Crime.test$crmrte))
```

## Combined models
Combining the predictors from the previous section with just the linear `pctmin` results in a mean error of `r round(error.lin2,4)`.

```{r}
# Splines with selected predictors
fit.spl2 = list()
pred.spl2 = list()
kf.error.spl2 = vector()
for (i in 1:length(folds)) {
  fit.spl2[[i]] = lm(crmrte ~ ns(pctmin, knots=pctmin.knots) + log(prbconv) + log(polpc) + prbarr + density:county + 
                       prbarr:prbpris + pctmin:polpc + polpc:wfed + density:pctmin +
                       density:pctymle + taxpc:wfed + region:wsta, data=Crime.train[-folds[[i]],])
  pred.spl2 = predict(fit.spl2[[i]], newdata=Crime.train[folds[[i]],])
  test.spl2.k = Crime.train[folds[[i]],]$crmrte
  kf.error.spl2[i] = mean(abs((pred.spl2 - test.spl2.k)/test.spl2.k))
}
best.index.spl2 = which.min(kf.error.spl2)
pred.spl2 = predict(fit.spl2[[best.index.spl2]], newdata=Crime.test, se.fit=TRUE)
error.spl2 = mean(abs((pred.spl2$fit-Crime.test$crmrte)/Crime.test$crmrte))
```

Finally, we included the splined version of `pctmin` predictor alongside the selected predictors, which resulted in a slight improvement in mean error to `r round(error.spl2, 4)`.
